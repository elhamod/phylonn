Running on GPUs 0,
{'embed_dim': 256, 'n_embed': 1024, 'ddconfig': {'double_z': False, 'z_channels': 256, 'resolution': 512, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 1, 2, 2, 4], 'num_res_blocks': 2, 'attn_resolutions': [16], 'dropout': 0.0}, 'lossconfig': {'target': 'taming.modules.losses.DummyLoss'}, 'phylomodel_params': {'embed_dim': 16, 'n_embed': 64, 'n_phylolevels': 4, 'codebooks_per_phylolevel': 4, 'n_phylo_channels': 32, 'resolution': 32, 'in_channels': 256, 'out_ch': 256, 'ch': 256}}
Working with z of shape (1, 256, 32, 32) = 262144 dimensions.
phylovqgan PhyloDisentangler(
  (conv_in): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (mlp_in): Sequential(
    (0): LayerNorm((32, 32, 32), eps=1e-05, elementwise_affine=True)
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Linear(in_features=32768, out_features=256, bias=True)
    (3): SiLU()
    (4): Unflatten(dim=1, unflattened_size=torch.Size([16, 4, 4]))
  )
  (mlp_out): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=256, out_features=32768, bias=True)
    (2): SiLU()
    (3): Unflatten(dim=1, unflattened_size=torch.Size([32, 32, 32]))
  )
  (quantize): VectorQuantizer2(
    (embedding): Embedding(64, 16)
  )
  (conv_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
PhyloDisentangler                        [1, 256, 32, 32]          --
├─Conv2d: 1-1                            [1, 256, 32, 32]          65,792
├─Sequential: 1-2                        [1, 16, 4, 4]             --
│    └─LayerNorm: 2-1                    [1, 32, 32, 32]           65,536
│    └─Flatten: 2-2                      [1, 32768]                --
│    └─Linear: 2-3                       [1, 256]                  8,388,864
│    └─SiLU: 2-4                         [1, 256]                  --
│    └─Unflatten: 2-5                    [1, 16, 4, 4]             --
├─VectorQuantizer2: 1-3                  [1, 16, 4, 4]             --
│    └─Embedding: 2-6                    [16, 16]                  1,024
├─Sequential: 1-4                        [1, 32, 32, 32]           --
│    └─Flatten: 2-7                      [1, 256]                  --
│    └─Linear: 2-8                       [1, 32768]                8,421,376
│    └─SiLU: 2-9                         [1, 32768]                --
│    └─Unflatten: 2-10                   [1, 32, 32, 32]           --
├─Conv2d: 1-5                            [1, 256, 32, 32]          65,792
==========================================================================================
Total params: 17,008,384
Trainable params: 17,008,384
Non-trainable params: 0
Total mult-adds (M): 151.63
==========================================================================================
Input size (MB): 1.05
Forward/backward pass size (MB): 4.72
Params size (MB): 68.03
Estimated Total Size (MB): 73.80
==========================================================================================
totalmodel PhyloVQVAE(
  (encoder): Encoder(
    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (down): ModuleList(
      (0): Module(
        (block): ModuleList(
          (0): ResnetBlock(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): ResnetBlock(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (attn): ModuleList()
        (downsample): Downsample(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
        )
      )
      (1): Module(
        (block): ModuleList(
          (0): ResnetBlock(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): ResnetBlock(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (attn): ModuleList()
        (downsample): Downsample(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
        )
      )
      (2): Module(
        (block): ModuleList(
          (0): ResnetBlock(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (1): ResnetBlock(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (attn): ModuleList()
        (downsample): Downsample(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        )
      )
      (3): Module(
        (block): ModuleList(
          (0): ResnetBlock(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): ResnetBlock(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (attn): ModuleList()
        (downsample): Downsample(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        )
      )
      (4): Module(
        (block): ModuleList(
          (0): ResnetBlock(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
          )
          (1): ResnetBlock(
            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (attn): ModuleList()
      )
    )
    (mid): Module(
      (block_1): ResnetBlock(
        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (attn_1): AttnBlock(
        (norm): GroupNorm(32, 512, eps=1e-06, affine=True)
        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
      )
      (block_2): ResnetBlock(
        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)
    (conv_out): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (decoder): Decoder(
    (conv_in): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (mid): Module(
      (block_1): ResnetBlock(
        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (attn_1): AttnBlock(
        (norm): GroupNorm(32, 512, eps=1e-06, affine=True)
        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
      )
      (block_2): ResnetBlock(
        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
        (dropout): Dropout(p=0.0, inplace=False)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (up): ModuleList(
      (0): Module(
        (block): ModuleList(
          (0): ResnetBlock(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): ResnetBlock(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (2): ResnetBlock(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (attn): ModuleList()
      )
      (1): Module(
        (block): ModuleList(
          (0): ResnetBlock(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))
          )
          (1): ResnetBlock(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (2): ResnetBlock(
            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)
            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (attn): ModuleList()
        (upsample): Upsample(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (2): Module(
        (block): ModuleList(
          (0): ResnetBlock(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): ResnetBlock(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (2): ResnetBlock(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (attn): ModuleList()
        (upsample): Upsample(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (3): Module(
        (block): ModuleList(
          (0): ResnetBlock(
            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
            (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
          )
          (1): ResnetBlock(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (2): ResnetBlock(
            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)
            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (attn): ModuleList()
        (upsample): Upsample(
          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
      (4): Module(
        (block): ModuleList(
          (0): ResnetBlock(
            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (1): ResnetBlock(
            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
          (2): ResnetBlock(
            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)
            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          )
        )
        (attn): ModuleList()
        (upsample): Upsample(
          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        )
      )
    )
    (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)
    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (loss): DummyLoss()
  (quantize): VectorQuantizer2(
    (embedding): Embedding(1024, 256)
  )
  (quant_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (post_quant_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  (phylo_disentangler): PhyloDisentangler(
    (conv_in): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (mlp_in): Sequential(
      (0): LayerNorm((32, 32, 32), eps=1e-05, elementwise_affine=True)
      (1): Flatten(start_dim=1, end_dim=-1)
      (2): Linear(in_features=32768, out_features=256, bias=True)
      (3): SiLU()
      (4): Unflatten(dim=1, unflattened_size=torch.Size([16, 4, 4]))
    )
    (mlp_out): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
      (1): Linear(in_features=256, out_features=32768, bias=True)
      (2): SiLU()
      (3): Unflatten(dim=1, unflattened_size=torch.Size([32, 32, 32]))
    )
    (quantize): VectorQuantizer2(
      (embedding): Embedding(64, 16)
    )
    (conv_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
  )
)
====================================================================================================
Layer (type:depth-idx)                             Output Shape              Param #
====================================================================================================
PhyloVQVAE                                         [1, 3, 512, 512]          --
├─Encoder: 1-1                                     [1, 256, 32, 32]          --
│    └─Conv2d: 2-1                                 [1, 128, 512, 512]        (3,584)
│    └─ModuleList: 2-2                             --                        --
│    │    └─Module: 3-1                            --                        (738,944)
│    │    └─Module: 3-2                            --                        (738,944)
│    │    └─Module: 3-3                            --                        (2,690,304)
│    │    └─Module: 3-4                            --                        (2,952,448)
│    │    └─Module: 3-5                            --                        (8,394,752)
│    └─Module: 2-3                                 --                        --
│    │    └─ResnetBlock: 3-6                       [1, 512, 32, 32]          (4,721,664)
│    │    └─AttnBlock: 3-7                         [1, 512, 32, 32]          (1,051,648)
│    │    └─ResnetBlock: 3-8                       [1, 512, 32, 32]          (4,721,664)
│    └─GroupNorm: 2-4                              [1, 512, 32, 32]          (1,024)
│    └─Conv2d: 2-5                                 [1, 256, 32, 32]          (1,179,904)
├─PhyloDisentangler: 1-2                           [1, 256, 32, 32]          --
│    └─Conv2d: 2-6                                 [1, 256, 32, 32]          65,792
│    └─Sequential: 2-7                             [1, 16, 4, 4]             --
│    │    └─LayerNorm: 3-9                         [1, 32, 32, 32]           65,536
│    │    └─Flatten: 3-10                          [1, 32768]                --
│    │    └─Linear: 3-11                           [1, 256]                  8,388,864
│    │    └─SiLU: 3-12                             [1, 256]                  --
│    │    └─Unflatten: 3-13                        [1, 16, 4, 4]             --
│    └─VectorQuantizer2: 2-8                       [1, 16, 4, 4]             --
│    │    └─Embedding: 3-14                        [16, 16]                  1,024
│    └─Sequential: 2-9                             [1, 32, 32, 32]           --
│    │    └─Flatten: 3-15                          [1, 256]                  --
│    │    └─Linear: 3-16                           [1, 32768]                8,421,376
│    │    └─SiLU: 3-17                             [1, 32768]                --
│    │    └─Unflatten: 3-18                        [1, 32, 32, 32]           --
│    └─Conv2d: 2-10                                [1, 256, 32, 32]          65,792
├─Conv2d: 1-3                                      [1, 256, 32, 32]          (65,792)
├─VectorQuantizer2: 1-4                            [1, 256, 32, 32]          --
│    └─Embedding: 2-11                             [1024, 256]               (262,144)
├─Conv2d: 1-5                                      [1, 256, 32, 32]          (65,792)
├─Decoder: 1-6                                     [1, 3, 512, 512]          --
│    └─Conv2d: 2-12                                [1, 512, 32, 32]          (1,180,160)
│    └─Module: 2-13                                --                        --
│    │    └─ResnetBlock: 3-19                      [1, 512, 32, 32]          (4,721,664)
│    │    └─AttnBlock: 3-20                        [1, 512, 32, 32]          (1,051,648)
│    │    └─ResnetBlock: 3-21                      [1, 512, 32, 32]          (4,721,664)
│    └─ModuleList: 2-14                            --                        --
│    │    └─Module: 3-22                           --                        (16,524,800)
│    │    └─Module: 3-23                           --                        (4,855,296)
│    │    └─Module: 3-24                           --                        (4,133,632)
│    │    └─Module: 3-25                           --                        (1,215,232)
│    │    └─Module: 3-26                           --                        (887,040)
│    └─GroupNorm: 2-15                             [1, 128, 512, 512]        (256)
│    └─Conv2d: 2-16                                [1, 3, 512, 512]          (3,459)
====================================================================================================
Total params: 83,891,843
Trainable params: 17,008,384
Non-trainable params: 66,883,459
Total mult-adds (G): 776.13
====================================================================================================
Input size (MB): 3.15
Forward/backward pass size (MB): 9024.57
Params size (MB): 335.57
Estimated Total Size (MB): 9363.29
====================================================================================================
accumulate_grad_batches = 1
Setting learning rate to 2.25e-05 = 1 (accumulate_grad_batches) * 1 (num_gpus) * 5 (batchsize) * 4.50e-06 (base_lr)
helloooooooo <generator object Module.parameters at 0x2aab7e513040>
Project config
model:
  base_learning_rate: 4.5e-06
  target: taming.models.phyloautoencoder.PhyloVQVAE
  params:
    embed_dim: 256
    n_embed: 1024
    ddconfig:
      double_z: false
      z_channels: 256
      resolution: 512
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 1
      - 2
      - 2
      - 4
      num_res_blocks: 2
      attn_resolutions:
      - 16
      dropout: 0.0
    lossconfig:
      target: taming.modules.losses.DummyLoss
    phylomodel_params:
      embed_dim: 16
      n_embed: 64
      n_phylolevels: 4
      codebooks_per_phylolevel: 4
      n_phylo_channels: 32
      resolution: 32
      in_channels: 256
      out_ch: 256
      ch: 256
data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 5
    num_workers: 8
    train:
      target: taming.data.custom.CustomTrain
      params:
        training_images_list_file: /home/elhamod/data/Fish/taming_transforms_fish_train_padded_512.txt
        size: 512
    validation:
      target: taming.data.custom.CustomTest
      params:
        test_images_list_file: /home/elhamod/data/Fish/taming_transforms_fish_test_padded_512.txt
        size: 512

Lightning config
trainer:
  profiler: simple
  distributed_backend: ddp
  gpus: 0,

Validation sanity check: 0it [00:00, ?it/s]Summoning checkpoint.
