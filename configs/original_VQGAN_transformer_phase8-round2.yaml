  model:
    base_learning_rate: 4.5e-06
    project: Phylo-VQVAE-transformer
    target: taming.models.cond_transformer.Net2NetTransformer
    params:
      cond_stage_key: class
      transformer_config:
        target: taming.modules.transformer.mingpt.GPT
        params:
          vocab_size: 1024
          block_size: 256 #16*16
          n_layer: 5
          n_head: 16
          n_embd: 1024

      first_stage_config:
        target: taming.models.vqgan.VQModel
        project: Phylo-VQVAE
        params:
          embed_dim: 256
          n_embed: 1024
          ckpt_path: /fastscratch/elhamod/logs/2023-01-09T18-13-38_Phylo-VQVAE-phase7256img-originalvqgan-imagenetbg-aug/checkpoints/last.ckpt
          ddconfig:
            double_z: False
            z_channels: 256
            resolution: 256
            in_channels: 3
            out_ch: 3
            ch: 128
            ch_mult: [ 1,1,2,2,4]  # num_down = len(ch_mult)-1
            num_res_blocks: 2
            attn_resolutions: [16]
            dropout: 0.0

          lossconfig:
            target: taming.modules.losses.DummyLoss

      cond_stage_config:
        target: taming.modules.misc.label_conditioner.LabelCond

  data:
    target: main.DataModuleFromConfig
    params:
      batch_size: 64 #32 #2
      num_workers: 8
      train:
        target: taming.data.custom.CustomTrain
        params:
          training_images_list_file: /fastscratch/elhamod/data/Fish/taming_transforms_fish_train_padded_256_imagenetmeancolor.txt
          size: 256
          add_labels: True
      validation:
        target: taming.data.custom.CustomTest
        params:
          test_images_list_file: /fastscratch/elhamod/data/Fish/taming_transforms_fish_test_padded_256_imagenetmeancolor.txt
          size: 256
          add_labels: True
