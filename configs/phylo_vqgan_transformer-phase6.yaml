model:
  base_learning_rate: 4.5e-06
  project: Phylo-VQVAE-transformer-phase6
  target: taming.models.cond_transformer.Phylo_Net2NetTransformer
  posttraining_ckpt: /fastscratch/elhamod/logs/2022-11-14T23-59-44_Phylo-VQVAE-phase6256img-phase6/checkpoints/epoch=000014.ckpt
  params:
    cond_stage_key: class # key to condition (label in this case)
    phyloModel: True
    top_k: 5
    transformer_config:
      target: taming.modules.transformer.mingpt.GPT
      params:
        vocab_size: 64 # size of codebook (number of possible codes)
        block_size: 65 # 32 attr+32 nonattr+1 cond# codes predicted at once.
        n_layer: 5
        n_head: 16 # relationships to learn
        n_embd: 32 #embedding dimensions for transformer. Does not have to be same as codebook but Ill pick same
    
    first_stage_config:
      target: taming.models.phyloautoencoder.PhyloVQVAE
      project: Phylo-VQVAE-phase6
      params:
        embed_dim: 256
        n_embed: 1024
        ddconfig:
          double_z: False
          z_channels: 256
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [ 1,1,2,2,4]  # num_down = len(ch_mult)-1
          num_res_blocks: 2
          attn_resolutions: [16]
          dropout: 0.0
        lossconfig:
          target: taming.modules.losses.DummyLoss

        phylomodel_params:
          embed_dim: 16
          n_embed: 64
          #
          n_phylolevels: 4
          n_levels_non_attribute: 4 
          codebooks_per_phylolevel: 8
          #
          n_phylo_channels: 64
          verbose: False
          #
          ch: 128
          n_mlp_layers: 2
          # NOT hyperparameters.
          resolution: 16
          in_channels: 256
          out_ch: 256

          lossconfig:
            target: taming.modules.losses.vqperceptual.VQLPIPSWithDiscriminator
            params:
              rec_weight: 1.0
              codebook_weight: 1.0
              disc_in_channels: 0
              disc_num_layers: 0
              disc_weight: 0.0
              disc_factor: 0.0
              perceptual_weight: 0.0
              disc_start: 10000
          
          lossconfig_phylo:
            target: taming.modules.losses.phyloloss.PhyloLoss
            params:
              phylo_weight: 0.1
              fc_layers: 2

              phyloDistances_string: "0.77,0.5,0.33"
              phylogenyconfig:
                target: taming.data.phylogeny.Phylogeny
                params:
                  filePath: /fastscratch/elhamod/data/Fish
          
          lossconfig_kernelorthogonality:
            target: taming.modules.losses.orthogonalloss.OrthogonalLoss
            params:
              weight: 1.0
              padding: 0
              stride: 1

          lossconfig_anticlassification:
            target: taming.modules.losses.anticlassificationloss.AntiClassificationLoss
            params:
              weight: 1.0
              beta: 0.7

    cond_stage_config:
      target: taming.modules.misc.label_conditioner.LabelCond
      params:
        num_of_classes: 38

data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 2
    num_workers: 8
    train:
      target: taming.data.custom.CustomTrain
      params:
        training_images_list_file: /fastscratch/elhamod/data/Fish/taming_transforms_fish_train_padded_256.txt
        size: 256
        add_labels: True
    validation:
      target: taming.data.custom.CustomTest
      params:
        test_images_list_file: /fastscratch/elhamod/data/Fish/taming_transforms_fish_test_padded_256.txt
        size: 256
        add_labels: True
